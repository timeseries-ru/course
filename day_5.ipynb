{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# День пятый - интерпретация, внедрение и другие темы\n",
    "\n",
    "Сегодня нас ждут:\n",
    "- некоторые методы локальной интерпретации\n",
    "- как создать веб-сервис на `flask`, как сохранить и загрузить модель\n",
    "- презентация `jupyter notebooks` на `voila` и немного `streamlit`\n",
    "- элементы мониторинга после внедрения\n",
    "\n",
    "факультативно:\n",
    "- немного о вероятностном программировании\n",
    "- вариационные автокодировщики (будем генерировать картинки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы интерпретации\n",
    "\n",
    "Как ранее уже упоминалось, методы интерпретации модели могут быть глобальными (как важность признаков у деревьев), а могут быть локальными, то есть теми, которые объясняют почему предсказание для конкретного примера именно такое.\n",
    "\n",
    "Сейчас мы рассмотрим библиотеку `shap` (`SHapely Additive exPlanations`, где в названии, *Shapely* - это фамилия), которая такие предсказания и позволяет делать. И делает это она благодаря некоторым результатам из теории игр.\n",
    "\n",
    "Представим себе признаки как игроков, а результат \"игры\" - это предсказание модели для этих признаков (разово). Тогда `shap` позволяет судить о вкладе каждого игрока в \"выигрыш\" (предсказание) - для этого рассматривается каждый поднабор из всех признаков (сочетания), от нуля признаков до всех. При добавлении признака в набор, он даёт некоторый вклад (эффект) в предсказание. Все эффекты для вхождений каждого признака количественно взвешиваются, они есть итоговый эффект каждого признака.\n",
    "\n",
    "А теперь представьте что у нас (всего) 10 признаков, это означает что нам надо перебрать `2**10` моделей (с различными наборами признаков). Мы, конечно, этим заниматься не будем, и благодаря библиотеке `shap`, умеющей во всевозможные оптимизации подобных вычислений и прочие ухищрения, всё получается быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole weight</th>\n",
       "      <th>shucked weight</th>\n",
       "      <th>viscera weight</th>\n",
       "      <th>shell weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.2415</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>1</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.2510</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  length  diameter  height  whole weight  shucked weight  \\\n",
       "4116    1   0.625     0.480   0.160        1.2415          0.6575   \n",
       "3563    2   0.575     0.455   0.155        0.8725          0.3490   \n",
       "2614    1   0.645     0.490   0.160        1.2510          0.5355   \n",
       "\n",
       "      viscera weight  shell weight  rings  \n",
       "4116          0.2625        0.2785      9  \n",
       "3563          0.2095        0.2850      8  \n",
       "2614          0.3345        0.3165      9  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# загрузим датасет ракушек\n",
    "data = pd.read_csv('data/abalone.csv')\n",
    "\n",
    "# немного препроцессинга\n",
    "data['sex'] = data.sex.apply(lambda sex: {\n",
    "    'F': 0, 'M': 1, 'I': 2\n",
    "}[sex])\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека `shap` может объяснять модели на базе деревьев (`TreeExplainer`), линейные (`LinearExplainer`, требуются независимые - они же несвязанные - признаки), нейронные сети `keras` (`DeepExplainer`), а также произвольные модели (`KernelExplainer`) - но увы весьма медленно.\n",
    "\n",
    "На данный момент, `TreeExplainer` не умеет в мультикласс, поэтом в этих случаях надо пользоваться универсальным `KernelExplainer`, и следует отметить, что он требует чтобы у модели был метод `predict_proba` (предсказывает вероятность - или уверенность - в классе). Таким методом обладают, например, все деревья.\n",
    "\n",
    "Мы же пока тем временем попробуем объяснить результаты работы регрессора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score 0.361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# отложим 100 сэмплов\n",
    "indices = shuffle(list(range(len(data))), random_state=1)\n",
    "train = indices[:-100]\n",
    "test = indices[-100:]\n",
    "\n",
    "regressor = GradientBoostingRegressor(\n",
    "    n_estimators=15, max_depth=7, random_state=1\n",
    ").fit(data.iloc[train,:-1], data.iloc[train, -1])\n",
    "\n",
    "print(\"test score %.3f\" % regressor.score(\n",
    "    data.iloc[test,:-1], data.iloc[test, -1]\n",
    "))\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor, data=data.iloc[test, :-1])\n",
    "shap_values_test = explainer.shap_values(data.iloc[test, :-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True rings value for first test sample = 11\n"
     ]
    }
   ],
   "source": [
    "print('True rings value for first test sample = %d' % data.iloc[test[0], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='iFUUAL1TV3VUK90SV0W6F'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"output value\"], \"baseValue\": 9.708563605191973, \"outValue\": 10.39095418654391, \"link\": \"identity\", \"featureNames\": [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \"shucked weight\", \"viscera weight\", \"shell weight\"], \"features\": {\"0\": {\"effect\": 0.17468861378729345, \"value\": 0.0}, \"1\": {\"effect\": -0.013966927025467157, \"value\": 0.52}, \"2\": {\"effect\": 0.17709431680850685, \"value\": 0.405}, \"3\": {\"effect\": -0.10699852368910796, \"value\": 0.14}, \"4\": {\"effect\": -0.08037174156401307, \"value\": 0.6915}, \"5\": {\"effect\": 0.44300155074335634, \"value\": 0.276}, \"6\": {\"effect\": 0.01794521200703457, \"value\": 0.13699999999999998}, \"7\": {\"effect\": 0.07099808028433471, \"value\": 0.215}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n",
       "    document.getElementById('iFUUAL1TV3VUK90SV0W6F')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values_test[0], data.iloc[test[0],:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На это диаграмме красным - то что добавило нам колец, а синим - то, что (для этой ракушки) убавило. Причем подписано сколько колец добавлено/убавлено. Лично я считаю, что для регрессии подобные объяснения очень наглядны. \n",
    "\n",
    "Для классификации есть же нечто, скажем так, поинтереснее, а именно `Alibi Trust Scores` - уровни доверия. Это мера соответствия между предсказанным классом, и тем, какие ближайшие соседи у этого класса. Условно, если предсказанный класс примера находится рядом с множеством подобных - тем больше мы можем верить предсказанию. А если не условно, то это как у `silhoutte_score` - отношение между расстоянием до ближайшего класса, отличного от предсказанного, к расстоянию до предсказанного класса. Следовательно, если эта величина больше 1, и чем она вообще больше, тем больше доверия к предсказанию.\n",
    "\n",
    "Попробуем предсказывать конкретно детский пол по остальным признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score 0.580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(\n",
    "    n_estimators=15, max_depth=3, random_state=1\n",
    ").fit(data.iloc[train,1:], data.iloc[train, 0])\n",
    "\n",
    "print(\"test score %.3f\" % classifier.score(\n",
    "    data.iloc[test,1:], data.iloc[test, 0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.confidence import TrustScore\n",
    "ts = TrustScore(\n",
    "    # тут могут быть настройки, но мы\n",
    "    # оставим всё по умолчанию\n",
    ")\n",
    "\n",
    "ts.fit(\n",
    "    data.iloc[train,1:].values,\n",
    "    data.iloc[train, 0].values,\n",
    "    classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class 0, predicted 2\n",
      "Proba 0.330, TrustScore 0.745, closest class 0\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict([data.iloc[test[0], 1:]])[0]\n",
    "print(\"True class %d, predicted %d\" % (\n",
    "    data.iloc[test[0], 0],\n",
    "    predicted\n",
    "))\n",
    "\n",
    "trust_scores, closest_classes = ts.score(\n",
    "    np.array([data.iloc[test[0], 1:]]),\n",
    "    np.array([predicted])\n",
    ")\n",
    "\n",
    "print(\"Proba %.3f, TrustScore %.3f, closest class %d\" % (\n",
    "    classifier.predict_proba(\n",
    "        data.iloc[test[0], 1:].values.reshape(1, -1)\n",
    "    )[0][0],\n",
    "    trust_scores[0], closest_classes[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут видим, `trust score < 1` , и ближайший класс точнее. Впрочем, здесь и вероятность предсказания не самая высокая (да и классификатор так себе).\n",
    "\n",
    "А сейчас мы рассмотрим технику, которая позволяет одновременно отбирать признаки и строить некоторую интерпретацию вида \"мы тут можем ошибаться на столько-то\" (*model perfomance prediction*). Нужно построить регрессор (в случае классификации - классификатор), который будет обучен (на отложенной валидации, поскольку стэкинг) предсказывать ошибки алгоритма.\n",
    "\n",
    "Посмотрим на эту позаимствованную (получается уже трижды) картинку.\n",
    "![MPP](media/mpp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple: r2 0.548, acc 0.300\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/abalone.csv')\n",
    "data = pd.get_dummies(data.sex).join(data.drop('sex', axis='columns'))\n",
    "\n",
    "indices = shuffle(list(range(len(data))), random_state=1)\n",
    "train = indices[:-1000]\n",
    "val = indices[-1000:-500]\n",
    "test = indices[-500:]\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "regressor = MLPRegressor(\n",
    "    [120, 120], random_state=1\n",
    ").fit(\n",
    "    data.iloc[train,:-1], data.iloc[train, -1]\n",
    ")\n",
    "\n",
    "classifier = MLPClassifier(\n",
    "    [120, 120], random_state=1\n",
    ").fit(\n",
    "    data.iloc[train,3:], data.iloc[train, :3]\n",
    ")\n",
    "\n",
    "print(\"simple: r2 %.3f, acc %.3f\" % (\n",
    "    regressor.score(data.iloc[test,:-1], data.iloc[test, -1]),\n",
    "    classifier.score(data.iloc[test,3:], data.iloc[test, :3])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "error_regressor = DecisionTreeRegressor(\n",
    "    random_state=1\n",
    ").fit(\n",
    "    data.iloc[val,:-1],\n",
    "    np.abs(\n",
    "        regressor.predict(data.iloc[val,:-1]) - data.iloc[val,-1]\n",
    "    )\n",
    ")\n",
    "\n",
    "error_classifier = DecisionTreeClassifier(\n",
    "    random_state=1\n",
    ").fit(\n",
    "    data.iloc[val,3:],\n",
    "    np.abs(\n",
    "        classifier.predict(data.iloc[val,3:]) - data.iloc[val,:3]\n",
    "    ).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили регрессор ошибки и классификатор ошибки. Их можно использовать и для отбора признаков (в обоих случаях уберем несколько признаков и посмотрим), и для проверки корректности предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected: r2 0.554, acc 0.362\n"
     ]
    }
   ],
   "source": [
    "redundand = 2\n",
    "regressor_features = np.array(data.columns)[:-1][\n",
    "    np.argsort(error_regressor.feature_importances_)\n",
    "][::-1][:-redundand]\n",
    "\n",
    "classifier_features = np.array(data.columns)[3:][\n",
    "    np.argsort(error_classifier.feature_importances_)\n",
    "][::-1][:-redundand]\n",
    "\n",
    "regressor = MLPRegressor(\n",
    "    [120, 120], random_state=1\n",
    ").fit(\n",
    "    data.loc[train, regressor_features], \n",
    "    data.iloc[train, -1]\n",
    ")\n",
    "\n",
    "classifier = MLPClassifier(\n",
    "    [120, 120], random_state=1\n",
    ").fit(\n",
    "    data.loc[train, classifier_features],\n",
    "    data.iloc[train, :3]\n",
    ")\n",
    "\n",
    "print(\"selected: r2 %.3f, acc %.3f\" % (\n",
    "    regressor.score(data.loc[test, regressor_features], data.iloc[test, -1]),\n",
    "    classifier.score(data.loc[test, classifier_features], data.iloc[test,:3])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы убрали по два признака, которые давали *наименьший вклад в объяснение ошибки*, это означает что они плохо объясняли различия между примерами. Давайте посмотрим на ошибку предсказания для конкретного примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression: True 8, Predicted 10.47, error 1.107\n",
      "classification: True [0, 1, 0], Predicted [0 0 0], is error [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"regression: True %d, Predicted %.2f, error %.3f\" % (\n",
    "    data.iloc[test[0], -1],\n",
    "    regressor.predict([data.loc[test[0], regressor_features]])[0],\n",
    "    error_regressor.predict([data.iloc[test[0], :-1]])[0]\n",
    "))\n",
    "\n",
    "print(\"classification: True %s, Predicted %s, is error %s\" % (\n",
    "    str(data.iloc[test[0], :3].values.astype(int).tolist()),\n",
    "    str(classifier.predict([data.loc[test[0], classifier_features]])[0]),\n",
    "    str(error_classifier.predict([data.iloc[test[0], 3:]])[0])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе тот же стэкинг, только целевая величина несколько другая. Стоит заметить, если бы качество моделей было бы выше, лучше бы и работали модели ошибок."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
