# Вопросы для самопроверки

Правильных ответов тут не будет, но будет 15 вопросов с вариантами ответов, которые позволят вспомнить содержание и поразмыслить над ним. Дело необязательное, скорее для тех, кому любопытно.

## Вопросы

**Чем алгоритм отличается от модели?**
1. Модель учится на примерах, а алгоритм дает некоторую ошибку,
2. Алгоритм создает модель, которая дает некоторую ошибку,
3. Алгоритм создает модель, используя данные, модель на данных дает некоторую ошибку,
4. Все неверно.

**Статистика, как функция от данных,**
1. Описывает данные некоторым образом,
2. Может быть случайной величиной,
3. Всегда может быть посчитана,
4. Все ответы правильные.

**Цикл `while` в `python` работает:**
1. Пока условие выполняется,
2. Пока условие не выполняется,
3. Может быть и так и так,
4. Бесконечно, пока не будет прерван.

**Массивы `numpy` нужны для того, чтобы**
1. Описывать многомерные величины,
2. Оперировать данными, как числами,
3. Сделать алгоритмы независимыми от размерности данных,
4. Для удобной работы с точки зрения python.

**Библиотеки визуализации `matplotlib` и `seaborn` позволяют**
1. Отображать произвольные данные в виде диаграмм,
2. Визуализировать зависимости между признаками,
3. Проводить анализ данных с помощью диаграмм,
4. Строить диаграммы по данным.

**Разведочный анализ данных можно ...**
1. Пропустить, если использовать сложные методы,
2. Проводить на случайных подвыборках данных, если данных много,
3. Использовать для препроцессинга признаков,
4. Использовать для построения гипотез о зависимости целевой переменной от признаков.

**Линейные модели**
1. Нужны когда данные связаны линейно,
2. Нужны когда данные не связаны линейно,
3. Слишком примитивны, чтобы вообще работать,
4. Можно использовать для моделирования нелинейных зависимостей.

**Следующие алгоритмы могут выходить за пределы целевой переменной на тренировочном множестве в случае регрессии**
1. Дерево решений,
2. Градиентный бустинг над решающими деревьями,
3. Случайный лес решающих деревьев,
4. Все перечисленные.

**Алгоритм ближайших соседей использует для предсказания ...**
1. Ближайшие к примеру примеры из тренировочного множества,
2. Ближайшие к примеру примеры из обоих множеств,
3. Все данные,
4. Расстояния между ближайшими точками на тренировочном множестве.

**Отбор признаков нужен когда их много, потому что**
1. Не все признаки одинаково влияют на целевую величину,
2. Сокращается время обучения алгоритмов,
3. Повышается качество предсказаний,
4. Все ответы верные.

**Понижение размерности - это алгоритм ...**
1. Обучения с учителем,
2. Обучения без учителя,
3. Препроцессинга признаков,
4. Ускорения обучения моделей.

**Кластеризация позволяет:**
1. Классифицировать объекты множества по группам,
2. Сгруппировать объекты по схожести,
3. Поделить датасет на непересекающиеся части,
4. Какие-то два ответа из предыдущих трёх верные.

**Метрики качества кластеризации -**
1. Субъективны,
2. Бесполезны,
3. Каждый раз должны быть разными под задачу,
4. Существуют.

**Прогнозирование одномерных временных рядов нужно для**
1. Использования в качестве признаков для других моделей путём стэкинга,
2. Извлечения компонент ряда и их анализа и использования в качестве признаков,
3. Собственно для получения прогноза,
4. Все перечисленное может иметь место.

**Нейросети получили широкое распространение, так как**
1. Не требуют большого количества данных,
2. Не требуют серьезной настройки,
3. Не требуют предобработки признаков,
4. Нет правильного ответа.

---

Надеюсь, всё это было интересно :)
