

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>День первый, обзорный &#8212; ML introduction</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-dropdown.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="День второй - анализ данных" href="day_2.html" />
    <link rel="prev" title="Курс “Введение в анализ данных и машинное обучение”" href="README.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">ML introduction</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="README.html">
   Курс “Введение в анализ данных и машинное обучение”
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   День первый, обзорный
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="day_2.html">
   День второй - анализ данных
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="day_3.html">
   День третий - обучение без учителя*
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="day_4.html">
   День четвертый - нейросети (изображения, тексты, многомерные ряды)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="day_5.html">
   День пятый - интерпретация, внедрение и другие темы
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cheatsheet.html">
   Как делать проекты
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="maths_behind.html">
   Визуально о математике, стоящей за некоторыми алгоритмами
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="recipes_book.html">
   Сборник полезных рецептов
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="self_check.html">
   Вопросы для самопроверки
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/day_1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/day_1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/day_1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.1 Определения алгоритма, модели, метрик и задач машинного обучения
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Пример
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     ВАЖНО!
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Заключение
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   1.2 Элементы теории вероятностей и математической статистики
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Пример
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     Описательные статистики
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Три важных теоремы
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     Заключение
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   1.3 А теперь… почему всё это работает
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probability-almost-correct-pac">
     Probability-almost-correct (PAC-) обучаемость
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     Заключение
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-jupyter-lab">
   1.4 Инструментарий аналитика данных: python и jupyter lab
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-crash-course">
     python crash course
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     Заключение
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   1.5 Цикл моделирования и кросс-валидация
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     Пример
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id16">
       1.5.1 Понимание задачи и целей
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id17">
       1.5.2 Разведочный анализ
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id18">
       1.5.3 Подготовка данных
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id19">
       1.5.4 Моделирование
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id20">
       1.5.5 Проверка качества
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     Заключение
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id22">
   1.6 Обзор всего курса на примерах предсказаний
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id23">
     Второй день - обучение с учителем
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id24">
     Третий день - задачи без учителя и временные ряды
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id25">
     Четвертый день - нейросети
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id26">
     Пятый день - интерпретация, презентация и внедрение моделей
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>День первый, обзорный<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>И сегодня нас ждут следующие темы:</p>
<ol class="simple">
<li><p>Определения и примеры,</p></li>
<li><p>Элементы теории вероятностей и математической статистики,</p></li>
<li><p>Немного о том, почему машинное обучение вообще работает,</p></li>
<li><p>Об инструментарии: <code class="docutils literal notranslate"><span class="pre">jupyter</span> <span class="pre">lab</span></code> и <code class="docutils literal notranslate"><span class="pre">python</span></code>,</p></li>
<li><p>Как делаются исследования в сфере анализа данных, процесс,</p></li>
<li><p>Обзор дальнейших разделов курса на примерах результатов.</p></li>
</ol>
<div class="section" id="id2">
<h2>1.1 Определения алгоритма, модели, метрик и задач машинного обучения<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>Формальные определения требуют владения серьезным математическим аппаратом. Мы попробуем обойтись без этого.</p>
<p>Самое первое, из того что нам понадобится, это понятие <strong>датасета</strong> (или <em>набора данных</em>). Это прямоугольная таблица значений, каждая строка которой называется <strong>пример</strong>, или же <strong>sample</strong>, а каждая колонка - <strong>признак</strong> или, что то же самое, <strong>feature</strong>.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Индекс примера</p></th>
<th class="head"><p>Признак_1</p></th>
<th class="head"><p>Признак_2</p></th>
<th class="head"><p>Признак_3</p></th>
<th class="head"><p>Признак_4</p></th>
<th class="head"><p>Признак_5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>10</p></td>
<td><p>20</p></td>
<td><p>“строка 1”</p></td>
<td><p>True</p></td>
<td><p>3.1415926</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>15</p></td>
<td><p>10</p></td>
<td><p>“строка 2”</p></td>
<td><p>False</p></td>
<td><p>2.71</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>12</p></td>
<td><p>40</p></td>
<td><p>“строка 3”</p></td>
<td><p>False</p></td>
<td><p>-1.12345</p></td>
</tr>
</tbody>
</table>
<p>Для <strong>задач обучения с учителем</strong>, один выбранный признак - вся колонка - объявляется как <strong>целевая величина</strong>, или <strong>target</strong> (часто обозначают как <code class="docutils literal notranslate"><span class="pre">y</span></code>), оставшиеся признаки мы так и будем называть признаками (features), их часто обозначают как <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
<blockquote>
<div><p>В задаче обучения с учителем, необходимо предсказывать целевую величину с помощью входных признаков. Она называется “с учителем”, потому что для ряда примеров у нас есть правильные ответы, и на них можно “научиться” предсказывать.</p>
<p>Для <strong>задач обучения без учителя</strong> - правильных ответов нет, и задача исследователя - найти некоторые полезные структуры в данных.</p>
</div></blockquote>
<p>Что позволяет научиться машине предсказывать ответы или исследовать данные?
Снова обойдемся без очень формальных определений, так как приведенные ниже определения сконструированы именно под этот курс.</p>
<ol class="simple">
<li><p><strong>Модель</strong> - это функция, которая принимает одно или более значений на входе, выдаёт значения на выходе (чаще всего одно - предсказание целевой величины),</p></li>
<li><p><strong>Метрика</strong> - это число, получаемое в результате сравнения известных правильных ответов, и тех, которыми отвечает модель. Иногда это можно называть ошибкой модели,</p></li>
<li><p><strong>Алгоритм</strong> - это инструкции, которые принимают на вход данные, а выдают на выходе <em>модель</em>.</p></li>
</ol>
<blockquote>
<div><p>В машинном обучении существует множество заготовленных <em>алгоритмов</em>, которые позволяют <em>по данным</em> строить <em>модели</em> так, чтобы <em>ошибка модели</em> была насколько это возможно меньше.</p>
</div></blockquote>
<p><img alt="Model Diagram" src="_images/diagram_model.svg" /></p>
<p>По типу значений <em>целевого признака</em> при обучении с учителем, задачи делят на как минимум следующие:</p>
<ol class="simple">
<li><p>Регрессия - когда целевой признак, это любое вещественное число (с запятой), например рост, вес, количество денег,</p></li>
<li><p>Классификация - когда целевой признак принимает значения из заранее заданного множества (да/нет, собака/кошка/лошадь/…).</p></li>
</ol>
</div>
<div class="section" id="id3">
<h2>Пример<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>Давайте рассмотрим пример алгоритма, модели и метрики. В этом разделе уже пойдет код, вдаваться в детали которого мы пока не будем, но в этом же лекционном дне далее станет ясно, что в нём происходит.</p>
<blockquote>
<div><p>Представим себе ситуацию, когда мы случайно попадаем на необитаемый остров, и видим незнакомый нам фрукт. С легкой руки назовём <em>мангустин</em>. Мы попробовали 10 таких фруктов, и составили таблицу.</p>
<p>Для каждого мангустина, мы некоторым образом знаем его размер в сантиметрах и вес в граммах, а также вкусный он или нет (да/нет).</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="c1"># магическая команда для отображения диаграмм в jupyter-тетрадках</span>

<span class="c1"># импорт библиотек</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># библиотека для удобной работы с массивами</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># библиотека для удобной работы с датасетами</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> <span class="c1"># библиотека для графики</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> <span class="c1"># библиотека для отображения диаграмм</span>

<span class="c1"># создадим наш датасет и наполним его синтетическими данными</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">125</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="c1"># 10 записей</span>
    <span class="s1">&#39;radius&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="c1"># еще десять записей,</span>
    <span class="s1">&#39;tasty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span> <span class="c1"># наш целевой признак</span>
<span class="p">})</span>

<span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>radius</th>
      <th>tasty</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>50.000000</td>
      <td>0.500000</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>58.333333</td>
      <td>0.833333</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>66.666667</td>
      <td>1.166667</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>75.000000</td>
      <td>1.500000</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>83.333333</td>
      <td>1.833333</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>91.666667</td>
      <td>2.166667</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>100.000000</td>
      <td>2.500000</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>108.333333</td>
      <td>2.833333</td>
      <td>True</td>
    </tr>
    <tr>
      <th>8</th>
      <td>116.666667</td>
      <td>3.166667</td>
      <td>True</td>
    </tr>
    <tr>
      <th>9</th>
      <td>125.000000</td>
      <td>3.500000</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Все наши знания о мангустинах приведены в этой таблице. Нам надо использовать некоторый алгоритм, который создаст модель для предсказания по размеру и весу - будет ли мангустин вкусным.
Сначала отобразим наши данные на плоскости, возможно это позволит сделать некоторые предположения.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;radius&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;tasty&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="p">);</span> <span class="c1"># зададим что по осям и что брать за цвет</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_10_0.png" src="_images/day_1_10_0.png" />
</div>
</div>
<p>Уже из данной диаграммы видно, что чем больше размер и вес, тем мангустин <em><strong>обычно</strong></em> вкуснее, но есть и исключения. Мы не будем особо мудрствовать, и используем следующий метод для построения модели</p>
<ol class="simple">
<li><p>Модель - пусть это функция <span class="math notranslate nohighlight">\(tasty = f(weight, radius) &gt; threshold = weight * a + radius * b &gt; threshold\)</span>, где <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, и <code class="docutils literal notranslate"><span class="pre">threshold</span></code> - называются параметрами модели,</p></li>
<li><p>Метрика (ошибка модели) - количество <em>неправильно</em> классифицированных примеров,</p></li>
</ol>
<p>Пусть <code class="docutils literal notranslate"><span class="pre">N</span></code> - количество примеров (известных нам мангустинов), и пусть наш алгоритм будет следующим:
$<span class="math notranslate nohighlight">\(a = \frac {max(weight) - min(weight)} {N},\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(b = \frac {max(radius) - min(radius)} {N},\)</span>$</p>
<p><code class="docutils literal notranslate"><span class="pre">threshold</span></code> же находится перебором с шагом 1 по всем записям, лучшим считается тот, который дает минимум нашей метрике.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># наша арифметическая модель</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">radius</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">radius</span> <span class="o">*</span> <span class="n">b</span> <span class="o">&gt;</span> <span class="n">threshold</span>

<span class="c1"># подсчет метрики как суммы несовпадающих ответов</span>
<span class="c1"># True соответствует 1, False соответствует 0</span>
<span class="k">def</span> <span class="nf">metric</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">!=</span> <span class="n">y_predicted</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">algorithm_create_model</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># здесь .max и .min - это всей колонке нашей таблицы</span>
    <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="n">best_metric</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># инициализируем бесконечностью</span>
    <span class="n">best_threshold</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="c1"># перебор будем вести до максимума значений до сравнения</span>
    <span class="n">model_maximum</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="n">b</span>
    
    <span class="c1"># для каждого порога</span>
    <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">model_maximum</span><span class="p">,</span> <span class="mf">1.</span><span class="p">):</span>
        <span class="n">y_predicted</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span> <span class="c1"># пройдем по всем примерам</span>
            <span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
                <span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                <span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">threshold</span>
            <span class="p">)</span>
            <span class="c1"># подсчитаем прогноз модели</span>
            <span class="n">y_predicted</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
        
        <span class="c1"># подсчитаем метрику по всем примерам</span>
        <span class="n">current_metric</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span>
            <span class="n">y_true</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">tasty</span><span class="p">,</span> 
            <span class="n">y_predicted</span><span class="o">=</span><span class="n">y_predicted</span>
        <span class="p">)</span>
        
        <span class="c1"># сверим, дает ли текущий порог лучше качество</span>
        <span class="c1"># и сохранием его, если так</span>
        <span class="k">if</span> <span class="n">current_metric</span> <span class="o">&lt;</span> <span class="n">best_metric</span><span class="p">:</span>
            <span class="n">best_metric</span> <span class="o">=</span> <span class="n">current_metric</span>
            <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">threshold</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Порог </span><span class="si">%.1f</span><span class="s2"> дал улучшение, неправильных ответов </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">threshold</span><span class="p">,</span> <span class="n">current_metric</span>
            <span class="p">))</span>
            
    <span class="k">return</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">best_threshold</span><span class="p">]</span>
            
<span class="n">algorithm_create_model</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Порог 0.0 дал улучшение, неправильных ответов 5
Порог 376.0 дал улучшение, неправильных ответов 4
Порог 438.0 дал улучшение, неправильных ответов 3
Порог 501.0 дал улучшение, неправильных ответов 2
Порог 563.0 дал улучшение, неправильных ответов 1
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[7.5, 0.3, 563.0]
</pre></div>
</div>
</div>
</div>
<div class="section" id="id4">
<h3>ВАЖНО!<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Мы “обучили” модель на всех доступных данных, и мы НЕ можем быть уверенными, что она их просто не запомнила.
Чтобы быть до некоторой степени уверенным, мы должны проверять качество модели на отложенном тестовом множестве.</p>
</div></blockquote>
<p>Перемешаем данные и проверим предсказания на трех отложенных мангустинах.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
    <span class="n">frac</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>  <span class="c1"># выберем все записи в случайном порядке</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span> <span class="c1"># зафиксируем генератор случайных чисел для воспроизводимости</span>
<span class="p">)</span>

<span class="c1"># отложим наши множества, в тестовом будет только три случая с конца</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>

<span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">algorithm_create_model</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="s2">&quot;Количество неправильных предсказаний из 3 тестовых: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metric</span><span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">tasty</span><span class="p">,</span>
    <span class="n">model</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">radius</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Порог 0.0 дал улучшение, неправильных ответов 4
Порог 536.0 дал улучшение, неправильных ответов 3
Порог 626.0 дал улучшение, неправильных ответов 2
Порог 715.0 дал улучшение, неправильных ответов 1
Порог 805.0 дал улучшение, неправильных ответов 0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Количество неправильных предсказаний из 3 тестовых: 1&#39;
</pre></div>
</div>
</div>
</div>
<p>Как видим, наша модель ошибается в 1 случае из 3. Можно догадаться, что она ошибается в том случае, когда метки нарушают возрастающий порядок в размерах и весе мангустина.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># посмотрим как предсказывает наша модель все данные и отобразим наши множества разными маркерами</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Истинные значения&quot;</span><span class="p">);</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;radius&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;tasty&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;is_test&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
    <span class="s2">&quot;radius&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="p">,</span>
    <span class="s2">&quot;tasty&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">tasty</span><span class="p">,</span>
    <span class="s2">&quot;is_test&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;test&quot;</span> <span class="k">if</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="n">test</span><span class="o">.</span><span class="n">index</span> <span class="k">else</span> <span class="s2">&quot;train&quot;</span> <span class="k">for</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span>
    <span class="p">]</span>
<span class="p">}));</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Предсказания&quot;</span><span class="p">);</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;radius&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;is_test&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
    <span class="s2">&quot;radius&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="p">,</span>
    <span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">radius</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">threshold</span><span class="p">),</span>
    <span class="s2">&quot;is_test&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;test&quot;</span> <span class="k">if</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="n">test</span><span class="o">.</span><span class="n">index</span> <span class="k">else</span> <span class="s2">&quot;train&quot;</span> <span class="k">for</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span>
    <span class="p">]</span>
<span class="p">}));</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_16_0.png" src="_images/day_1_16_0.png" />
</div>
</div>
</div>
<div class="section" id="id5">
<h3>Заключение<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>В данном курсе мы в основном не будем составлять собственные алгоритмы, а будем пользоваться уже готовыми. Их много, и работают они хорошо в разных случаях. За каждым из них стоит некоторая своя <em>интуиция</em>, как в случае алгоритма выше стояла следующая: чем выше размер и вес мангустина - тем он, начиная с некоторого порога, вкусный.</p>
<p>Другие данные могут давать (совсем) другие подсказки, и поэтому мы уделим внимание и разведочному анализу данных, цель которого - найти эти подсказки в данных и выбрать алгоритм получше.</p>
<p>Также из основного, следует понимать, что <strong>мы обязаны</strong> проверять качество на тех данных, которые модель не видела, что избежать самообмана. Модели, как и люди, могут запоминать правильные ответы (и далее мы даже увидим построенный на это алгоритм), и ничего <em><strong>не обобщать</strong></em> <em>(no generalization)</em>. Отсутствие обобщения - это то, чего мы будем избегать, стараясь при этом минимизировать ошибку.</p>
</div>
</div>
<div class="section" id="id6">
<h2>1.2 Элементы теории вероятностей и математической статистики<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>Начнем с того, что всё что случайно, как ни странно, случайно по-разному. Например, и монетка, и игральный кубик - с равной вероятностью выдают свои исходы. Но, например, попадание выпущенной из лука стрелой “в десяточку” - тяготеет все же к этой самой десяточке, хотя и случайным образом в неё иногда не попадает.</p>
<p>Как и в случае с алгоритмами и моделями, мы в рамках этого курса не будем вдаваться во все математические детали определений (хотя они очень важны). Ограничимся лишь тем, что нам потребуется.</p>
<p><strong>Случайная величина</strong> - это величина, принимающая какой-либо исход из множества для неё возможных. Например, случайная величина на <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1)</span></code> принимает значения только из этого интервала (<em>непрерывная</em> случайная величина, её исходы всегда между нулем и единицей). Или, случайная величина может принимать два исхода <code class="docutils literal notranslate"><span class="pre">{-1;</span> <span class="pre">1}</span></code> - <em>дискретная</em> случайная величина.</p>
<p><strong>Вероятность</strong> - это число от 0 до 1 (включительно), характеризующее, условно, как часто мы в конкретный исход попадём, или же насколько <em>мы верим</em> в то, что он произойдет (это так, если мы еще ни разу не проводили испытаний).</p>
<blockquote>
<div><p>Например, для дискретной величины <code class="docutils literal notranslate"><span class="pre">{-1,</span> <span class="pre">1}</span></code>, если вероятность для <code class="docutils literal notranslate"><span class="pre">-1</span></code> равна <code class="docutils literal notranslate"><span class="pre">0.3</span></code>, мы будем считать что это означает, что в 100 испытаниях нам выпадет <code class="docutils literal notranslate"><span class="pre">-1</span></code> как раз 30 раз.
Для непрерывной, вероятность определяется не в точке, а в луче: вероятность что <code class="docutils literal notranslate"><span class="pre">величина</span> <span class="pre">&lt;</span> <span class="pre">0.5</span></code> равна <code class="docutils literal notranslate"><span class="pre">0.3</span></code>, означает что в точках менее 0.5 величина будет в 3 случаях из 10.</p>
</div></blockquote>
<p>Формально, определения немного (если не сказать совершенно) другие. Но для наших нужд такого подхода будет достаточно.</p>
<p><strong>Функция распределения случайной величины</strong> - описывает как раз все вероятности для всех исходов. То есть <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">F(x)</span> <span class="pre">&lt;</span> <span class="pre">1</span></code>, для любого <code class="docutils literal notranslate"><span class="pre">x</span></code> из множества исходов величины. <em>Плотность распределения</em> - это производная функции распределения (её определенный интеграл даёт вероятность).</p>
<p>Давайте на примерах.</p>
<p>Посмотрим на <em>равномерно</em> распределенную на (0, 1) случайную величину. Равномерно, это означает что чем длинее отрезок, тем пропорционально выше вероятность попасть в него.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># массив, где будут наши случайные величины</span>

<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span> <span class="c1"># цикл от 0 до 999</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span>
    
<span class="c1"># и отобразим количество попаданий точки это величины</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">kde</span><span class="o">=</span><span class="kc">False</span> <span class="c1"># не делать оценку плотности распределения</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_21_0.png" src="_images/day_1_21_0.png" />
</div>
</div>
<p>Рассмотрим распределенную на (-Infinity, +Infinity) случайную величину, со средним значением в числе 10, и такую чтобы её значения с чуть более чем 95%-вероятностью попадали в диапазон от +5 до +15.</p>
<p>Для того, чтобы значения <em>нормально распределенной случайной величины</em> (это значит функция распределения имеет определенный заданный вид, пока не суть какой) в более чем 95% случаев лежали в заданном диапазоне <code class="docutils literal notranslate"><span class="pre">(среднее</span> <span class="pre">-</span> <span class="pre">L,</span> <span class="pre">среднее</span> <span class="pre">+</span> <span class="pre">L)</span></code>, нужно задать её <em>стандартное отклонение</em> как <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">/</span> <span class="pre">2</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># массив, где будут наши случайные величины</span>

<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span> <span class="c1"># цикл от 0 до 9999</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
        <span class="mi">10</span><span class="p">,</span> <span class="c1"># среднее</span>
        <span class="mf">2.5</span> <span class="c1"># это половина ширины диапазона        </span>
    <span class="p">))</span>

<span class="c1"># и отобразим количество попаданий точки это величины</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">kde</span><span class="o">=</span><span class="kc">False</span> <span class="c1"># не делать оценку плотности распределения</span>
<span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;Среднее&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">600</span><span class="p">),</span> <span class="n">arrowprops</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;arrowstyle&quot;</span><span class="p">:</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">});</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;Здесь лежат около 95% исходов&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_23_0.png" src="_images/day_1_23_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Подсчитаем процент попавших в диапазон от +5 до +15 точек</span>
<span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">5</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">15</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9522
</pre></div>
</div>
</div>
</div>
<p>Случай дискретных величин выглядит слегка вырожденно.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.3</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_26_0.png" src="_images/day_1_26_0.png" />
</div>
</div>
<p><strong>Задача теории вероятностей</strong> - это уметь описывать случайные величины.</p>
<p><strong>Задача математической статистики</strong> - обратная. По выборке из случайных значений, определить что это за величина (её свойства).
Любая функция от выборки - например среднее значение, или самое часто встречающееся (в статистике - <em>мода</em>), - называется <em>статистикой</em>.</p>
<p>Анализ данных и машинное обучение - это в некотором смысле продолжение статистики, так как мы по случайной выборке (датасету) должны установить зависимость между признаками и целевой величиной.</p>
<div class="section" id="id7">
<h3>Пример<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>Представим, что у нас есть замеры роста 300 человек. Мы не знаем что это за случайная величина, но мы можем рассмотреть её различные описательные статистики, и что-то сказать о её поведении.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">height</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span> <span class="c1"># синтетические данные</span>
<span class="p">]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_30_0.png" src="_images/day_1_30_0.png" />
</div>
</div>
</div>
<div class="section" id="id8">
<h3>Описательные статистики<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;height&#39;</span> <span class="p">:</span> <span class="n">height</span><span class="p">})</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>height</th>
      <td>300.0</td>
      <td>169.946306</td>
      <td>5.105498</td>
      <td>155.887814</td>
      <td>166.682206</td>
      <td>169.878066</td>
      <td>173.098361</td>
      <td>187.517009</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Здесь мы видим:</p>
<ul class="simple">
<li><p>количество (count) записей,</p></li>
<li><p>среднее (mean) для всех замеров роста,</p></li>
<li><p>стандартное отклонение (std) - для нормального распределения, 95% данных лежат в интервале (<code class="docutils literal notranslate"><span class="pre">среднее</span> <span class="pre">-</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">стандартное</span> <span class="pre">отклонение</span></code>, <code class="docutils literal notranslate"><span class="pre">среднее</span> <span class="pre">+</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">стандартное</span> <span class="pre">отклонение</span></code>),</p></li>
<li><p>25% данных ниже значения, указанного в столбце 25%</p></li>
<li><p>аналогично с другими процентными значениями (эти статитистики называются процентилями),</p></li>
<li><p>минимум и максимум по всем данным.</p></li>
</ul>
</div>
<div class="section" id="id9">
<h3>Три важных теоремы<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p><strong>Закон больших чисел</strong>: если все случайные величины у нас независимы и одинаково распределены, то <em><strong>выборочное среднее</strong></em> стремится при увеличении числа испытаний к <em><strong>математическому ожиданию</strong></em>.</p>
<p>Математическое ожидание - это взвешенные по вероятностям исходы, то есть в дискретном случае,</p>
<div class="math notranslate nohighlight">
\[E[x] = \sum p_i x_i,\]</div>
<p>где <span class="math notranslate nohighlight">\(x_i\)</span> - исходы (значения) случайной величины, а <span class="math notranslate nohighlight">\(p_i\)</span> - их вероятность.</p>
<p>По сути, это означает, что в условиях незнания среднего по всем возможным ситуациям (по “всем данным в мире”), мы можем при большом количестве данных заменить его выборочным средним. В нашем при мере с ростом, это означает, что средний рост по всё более увеличивающейся выборке будет ближе к некоторому истинному значению (по “всем данным в мире”).</p>
<p><strong>Центральная предельная теорема</strong>: для независимых случайных величин из одного распределения со средним <span class="math notranslate nohighlight">\(M\)</span> и стандартным отклонением <span class="math notranslate nohighlight">\(S\)</span>, их выборочное среднее стремится (при увеличении количества испытаний <span class="math notranslate nohighlight">\(n\)</span>) к нормальному распределению с тем же средним и разбросом <span class="math notranslate nohighlight">\(\frac {S} {\sqrt n}\)</span>.</p>
<p>Возвращаясь к нашему примеру с ростом, это означает, что по мере роста выборки, средний рост будет распределен как нормальная случайная величина, и чем точнее нам нужно его измерять - тем больше данных нам нужно.</p>
<p><strong>Условная вероятность и теорема Байеса</strong></p>
<p>Тут мы подходим к одному из краеугольных камней машинного обучения. Начнем с двух вопросов:</p>
<ol class="simple">
<li><p>Насколько вероятно, что через час будет дождь? Пусть это <span class="math notranslate nohighlight">\(A\)</span></p></li>
<li><p>Насколько вероятно, что через час будет дождь, если он уже идёт? Пусть вероятность дождя сейчас <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
</ol>
<p>Без математики понятно, что речь идёт о разных ситуациях, что в математике формализуют как <em>условную вероятность</em> (определение):</p>
<div class="math notranslate nohighlight">
\[P(A|B) = \frac {P(A \cap B)} {P(B) }\]</div>
<p>где <span class="math notranslate nohighlight">\(\cap\)</span> обозначает <code class="docutils literal notranslate"><span class="pre">И</span></code> (пересечение множеств), то есть совместную вероятность обоих случаев сразу.</p>
<p>Практически из определения, вытекает <strong>теорема Байеса</strong>:</p>
<div class="math notranslate nohighlight">
\[P(A|B) = \frac {P(B|A) * P(A)} {P(B)}\]</div>
<p>В терминах дождей, это означает, что
<code class="docutils literal notranslate"><span class="pre">вероятность</span> <span class="pre">что</span> <span class="pre">дождь</span> <span class="pre">будет</span> <span class="pre">через</span> <span class="pre">час,</span> <span class="pre">если</span> <span class="pre">он</span> <span class="pre">идёт</span> <span class="pre">сейчас</span> <span class="pre">=</span> <span class="pre">вероятность</span> <span class="pre">дождя</span> <span class="pre">сейчас,</span> <span class="pre">если</span> <span class="pre">он</span> <span class="pre">будет</span> <span class="pre">через</span> <span class="pre">час</span> <span class="pre">*</span> <span class="pre">вероятность</span> <span class="pre">дождя</span> <span class="pre">через</span> <span class="pre">час</span> <span class="pre">/</span> <span class="pre">вероятность</span> <span class="pre">дождя</span> <span class="pre">сейчас</span></code>.</p>
<p>В данном примере мы ничего напрямую не выигрываем от теоремы (если только мы не метеорологи), но давайте рассмотрим другую, более практическую задачу.</p>
<p>Есть две корзины с печеньем:</p>
<ol class="simple">
<li><p>В первой 30 ванильных и 10 шоколадных,</p></li>
<li><p>Во второй - 20 ванильных и 20 шоколадных.</p></li>
</ol>
<p>Мы в темноте вытаскиваем наугад из какой-то корзины ванильное печение. Какова вероятность, что мы вытащили её из первой?</p>
<blockquote>
<div><p>Жизненный опыт подсказывает, что скорее всего из первой, так как в ней больше ванильных. Теорема Байеса же скажет, что вероятность вытащить из первой равна произведению вероятностей выбрать первую корзину <span class="math notranslate nohighlight">\(P(A)\)</span>, выбрать из неё ванильную <span class="math notranslate nohighlight">\(P(B | A)\)</span>, и всё это поделить на вероятность вытащить ванильную из всех корзин <span class="math notranslate nohighlight">\(P(B)\)</span>.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span> <span class="c1"># вытаскиваем из случайной корзины. это наше A</span>

<span class="n">likelihood</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">4</span> <span class="c1"># вероятность ванильной печеньки в первой корзине. это наше P(B|A)</span>

<span class="n">evidence</span> <span class="o">=</span> <span class="p">(</span><span class="mi">30</span> <span class="o">+</span> <span class="mi">20</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">20</span> <span class="o">+</span> <span class="mi">30</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># вероятность вытащить ванильную печеньку вообще из всех корзин. P(B)</span>

<span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span> <span class="o">/</span> <span class="n">evidence</span>

<span class="k">assert</span> <span class="n">posterior</span> <span class="o">==</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">5</span> <span class="c1"># выбросим ошибку, если равенство не выполняется</span>
<span class="n">posterior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6
</pre></div>
</div>
</div>
</div>
<p>Это конечно замечательно, что мы можем сказать <em>вероятность</em>, конечно, но какая польза от всего этого? А польза в рамках анализа данных и машинного обучения, следующая. Задачу машинного обучения часто ставят как поиск параметров, таких что:</p>
<p><code class="docutils literal notranslate"><span class="pre">максимум</span> <span class="pre">вероятности</span> <span class="pre">получить</span> <span class="pre">(параметры</span> <span class="pre">|</span> <span class="pre">датасета)</span></code>, и поскольку такую вероятность мы саму по себе не знаём, то “проворачивают ручку Байеса”:</p>
<p><code class="docutils literal notranslate"><span class="pre">вероятность</span> <span class="pre">(параметров</span> <span class="pre">|</span> <span class="pre">данные)</span> <span class="pre">=</span> <span class="pre">вероятность</span> <span class="pre">данных</span> <span class="pre">при</span> <span class="pre">параметрах</span> <span class="pre">*</span> <span class="pre">вероятность</span> <span class="pre">параметров</span> <span class="pre">/</span> <span class="pre">вероятность</span> <span class="pre">данных</span></code>.</p>
<p>При максимизации вероятности слева, знаменатель справа не меняется (он не зависит от параметров модели), поэтому его даже не всегда считают. Если говорить простыми словами - при машинном обучении часто ищутся те параметры модели, которые имеют максимальную вероятность для имеющегося датасета.</p>
</div>
<div class="section" id="id10">
<h3>Заключение<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>Мы не будем напрямую пользоваться указанными теоремами. Нам важно следующее следствие:</p>
<blockquote>
<div><p>Чем больше в выборке наблюдений, тем лучше можно оценивать характеристики процесса генерации “всех данных в мире” (<em>data generation process</em>). Но поскольку у нас есть только выборка, то инструменты математической статистики очень пригождаются в анализе данных и машинном обучении.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="id11">
<h2>1.3 А теперь… почему всё это работает<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Если вы до этого чего-то не поняли, или вообще ничего не поняли, не расстраивайтесь.</p>
<p>Сейчас будет еще сложнее.</p>
<p>Обрадую - после этого будет всё только практика, и сравнительно легко по сравнению с тем, о чем будет сейчас.</p>
</div></blockquote>
<div class="section" id="probability-almost-correct-pac">
<h3>Probability-almost-correct (PAC-) обучаемость<a class="headerlink" href="#probability-almost-correct-pac" title="Permalink to this headline">¶</a></h3>
<p>Всё это конечно замечательно, запустить алгоритм на данных, который нам выдаст модель, которая уловила в данных какие-то закономерности с некоторой ошибкой… А что если данных много, они большие, и их вообще человеку не понять? Не будем же мы проверять каждый ответ руками, смысл?</p>
<p><strong>Вопрос</strong>: можем ли мы верить моделям даже в пределах их ошибки?</p>
<p><strong>Ответ</strong>: да, но не всегда.</p>
<p>Что вообще означает, что алгоритм может выдать обучившуюся модель? Пусть у нас есть некоторый алгоритм, который выдал на данных нам модель, которая работает с некоторой ошибкой.</p>
<p>Рассмотрим следующие понятия:</p>
<ul class="simple">
<li><p>Ошибка генерализации - среднее значение ошибки на всех данных в мире. Мы её не знаем на самом деле.</p></li>
<li><p>Ошибка модели на тренировочном/тестовом множестве - среднее значение ошибки на выбранном известном множестве.</p></li>
<li><p>Желательно бы построить такую модель, которая будучи обученной на известном множестве, имела бы <strong>минимальную ошибку генерализации</strong>.</p></li>
</ul>
<p>Алгоритм называется PAC-обучаемым, если</p>
<ol class="simple">
<li><p>Выбрав порог ошибки <code class="docutils literal notranslate"><span class="pre">E</span></code>, например не более 1% в среднем от любых входных данных,</p></li>
<li><p>Фиксируя нашу уверенность <code class="docutils literal notranslate"><span class="pre">P</span></code> (это некоторая вероятность),</p></li>
<li><p>Будет иметь место факт: существует количество данных <code class="docutils literal notranslate"><span class="pre">n</span></code>, выше которого вероятность ошибки выше <code class="docutils literal notranslate"><span class="pre">E</span></code> ниже <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">P</span></code>.</p></li>
</ol>
<blockquote>
<div><p>То есть, алгоритм выдаёт такую модель, которая даёт ошибку в <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">P</span></code> случаев выше чем <code class="docutils literal notranslate"><span class="pre">E</span></code>, начиная с некоторого числа примеров <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
</div></blockquote>
<p>Существует даже формула на такой размер данных. Но она нам не нужна, все равно мы тут данные не генерируем :)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># один из примеров такой формулы - для задачи классификации</span>
<span class="c1"># конкретно эта работает только в случае, если алгоритм выдает конечное число моделей</span>

<span class="k">def</span> <span class="nf">estimate_error</span><span class="p">(</span><span class="n">models_number</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">error_probability</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">models_number</span> <span class="o">/</span> <span class="n">error_probability</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_size</span>

<span class="s2">&quot;Для миллиарда моделей и трехста примеров, с вероятностью 99</span><span class="si">%%</span><span class="s2"> - оценка ошибки классификатора будет менее: </span><span class="si">%.4f</span><span class="s2"> (доля неправильных ответов)&quot;</span> <span class="o">%</span> <span class="n">estimate_error</span><span class="p">(</span><span class="mi">10</span> <span class="o">**</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Для миллиарда моделей и трехста примеров, с вероятностью 99% - оценка ошибки классификатора будет менее: 0.0844 (доля неправильных ответов)&#39;
</pre></div>
</div>
</div>
</div>
<p>Миллиард моделей - это не так уж и много. Тем не менее, компьютерные алгоритмы выдают конечное число моделей - так как точность компьютерных чисел не бесконечная (но очень большая).
<strong>Вывод</strong>: формулы сами по себе не очень полезны: количество моделей подсчитать трудно. Да и не нужно.</p>
<p>Мы попробуем на синтетических данных убедиться, что с ростом количества данных алгоритмы работают лучше.</p>
<p>Рассмотрим пример с ростом человека. Есть все люди мира, какие только могут быть, у нас же только ограниченная выборка, по которой мы можем делать выводы. Так вот, представим что мы хотим предсказывать вес человека по росту, тогда для PAC-обучаемого алгоритма с ростом обучающей выборки должно расти качество.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weight</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">sample</span> <span class="o">-</span> <span class="mi">110</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">height</span>
<span class="p">]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="n">height</span><span class="p">}));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_49_0.png" src="_images/day_1_49_0.png" />
</div>
</div>
<p>Мы рассмотрим три алгоритма. Линейный (<span class="math notranslate nohighlight">\(y = kx + b\)</span>, где <code class="docutils literal notranslate"><span class="pre">k</span></code> и <code class="docutils literal notranslate"><span class="pre">b</span></code> такие, чтобы ошибка была наименьшей), алгоритм, строящий решающее дерево (набор правил вида <code class="docutils literal notranslate"><span class="pre">если</span> <span class="pre">x</span> <span class="pre">&gt;</span> <span class="pre">5,</span> <span class="pre">то</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">2</span></code>) и алгоритм ближайших соседей. Второй мы рассмотрим в двух вариантах - с обрезкой по глубине (по количеству вопросов) и без, и метод ближайших соседей, который запоминает данные и выдает усредненные значения по нескольким соседям.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># эта магическая команда замеряет время работы ячейки Jupyter</span>

<span class="c1"># импортируем алгоритм, строящий линейные модели</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># импортируем алгоритм решающего дерева</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="c1"># импортируем алгоритм ближайших соседей</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>

<span class="c1"># импортируем подсчет средней абсолютной ошибки</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Учимся на увеличивающемся количестве точек по сотне раз,</span>
<span class="s2">качество проверяем на &quot;всех данных в мире&quot; - усредняем.</span>
<span class="s2">Ошибкой считаем разницу более одного килограмма.</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;deep tree&#39;</span><span class="p">,</span> <span class="s1">&#39;shallow tree&#39;</span><span class="p">,</span> <span class="s1">&#39;neighbors&#39;</span>
<span class="p">]</span>
<span class="k">for</span> <span class="n">number_points</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">31</span><span class="p">):</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">name</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">estimator_names</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">random_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight</span><span class="p">),</span>
            <span class="n">size</span><span class="o">=</span><span class="n">number_points</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span>
            <span class="n">LinearRegression</span><span class="p">(),</span>
            <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">)</span>
        <span class="p">]):</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">height</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="n">random_indices</span><span class="p">],</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weight</span><span class="p">)[</span><span class="n">random_indices</span><span class="p">]</span>
            <span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">height</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">errors</span><span class="p">[</span><span class="n">estimator_names</span><span class="p">[</span><span class="n">iterator</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
            <span class="p">)</span>
    <span class="n">percents</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">:</span>
        <span class="n">percents</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
            <span class="mi">1</span> <span class="k">if</span> <span class="n">error</span> <span class="o">&gt;</span> <span class="mf">1.</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">error</span> <span class="ow">in</span> <span class="n">errors</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="p">])</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">([</span>
            <span class="n">number_points</span><span class="p">,</span>
            <span class="n">percents</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
            <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">errors</span><span class="p">[</span><span class="n">name</span><span class="p">]),</span>
            <span class="n">name</span>
        <span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;Шаг </span><span class="si">%d</span><span class="s2"> процент &quot;плохих&quot; моделей: линейный алгоритм: %.f, глубокое дерево: %.f, неглубокое дерево %.f, соседи %.f&quot;&quot;&quot;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">number_points</span><span class="p">,</span>
        <span class="n">percents</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span>
        <span class="n">percents</span><span class="p">[</span><span class="s1">&#39;deep tree&#39;</span><span class="p">],</span>
        <span class="n">percents</span><span class="p">[</span><span class="s1">&#39;shallow tree&#39;</span><span class="p">],</span>
        <span class="n">percents</span><span class="p">[</span><span class="s1">&#39;neighbors&#39;</span><span class="p">]</span>
    <span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Учимся на увеличивающемся количестве точек по сотне раз,
качество проверяем на &quot;всех данных в мире&quot; - усредняем.
Ошибкой считаем разницу более одного килограмма.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 5 процент &quot;плохих&quot; моделей: линейный алгоритм: 29, глубокое дерево: 100, неглубокое дерево 100, соседи 100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 6 процент &quot;плохих&quot; моделей: линейный алгоритм: 19, глубокое дерево: 100, неглубокое дерево 100, соседи 100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 7 процент &quot;плохих&quot; моделей: линейный алгоритм: 13, глубокое дерево: 100, неглубокое дерево 100, соседи 100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 8 процент &quot;плохих&quot; моделей: линейный алгоритм: 4, глубокое дерево: 100, неглубокое дерево 100, соседи 100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 9 процент &quot;плохих&quot; моделей: линейный алгоритм: 4, глубокое дерево: 100, неглубокое дерево 100, соседи 100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 10 процент &quot;плохих&quot; моделей: линейный алгоритм: 6, глубокое дерево: 100, неглубокое дерево 100, соседи 100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 11 процент &quot;плохих&quot; моделей: линейный алгоритм: 4, глубокое дерево: 100, неглубокое дерево 100, соседи 98
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 12 процент &quot;плохих&quot; моделей: линейный алгоритм: 2, глубокое дерево: 100, неглубокое дерево 100, соседи 98
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 13 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 100, неглубокое дерево 100, соседи 99
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 14 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 100, неглубокое дерево 100, соседи 98
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 15 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 97, неглубокое дерево 100, соседи 95
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 16 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 95, неглубокое дерево 99, соседи 91
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 17 процент &quot;плохих&quot; моделей: линейный алгоритм: 1, глубокое дерево: 98, неглубокое дерево 100, соседи 95
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 18 процент &quot;плохих&quot; моделей: линейный алгоритм: 1, глубокое дерево: 100, неглубокое дерево 100, соседи 96
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 19 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 100, неглубокое дерево 100, соседи 91
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 20 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 99, неглубокое дерево 100, соседи 88
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 21 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 95, неглубокое дерево 100, соседи 87
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 22 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 95, неглубокое дерево 100, соседи 83
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 23 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 89, неглубокое дерево 100, соседи 77
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 24 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 88, неглубокое дерево 100, соседи 67
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 25 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 88, неглубокое дерево 100, соседи 71
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 26 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 87, неглубокое дерево 100, соседи 64
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 27 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 85, неглубокое дерево 100, соседи 60
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 28 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 82, неглубокое дерево 99, соседи 61
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 29 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 74, неглубокое дерево 99, соседи 57
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Шаг 30 процент &quot;плохих&quot; моделей: линейный алгоритм: 0, глубокое дерево: 79, неглубокое дерево 100, соседи 40
Wall time: 8.96 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;points&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;percent&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;type&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span>
    <span class="s1">&#39;points&#39;</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">,</span> <span class="s1">&#39;error&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span>
<span class="p">]));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_52_0.png" src="_images/day_1_52_0.png" />
</div>
</div>
<p>Из этого изображения вовсе не следует, что линейный алгоритм вот лучше всех (но на этих данных, да, лучше). Это иллюстрация связи “всех данных в мире” и уменьшения ошибки с ростом количества данных (как видим с разной скоростью). Почему здесь линейный случай лучше всего работает - да потому что изначально в наши синтетических данных линейная связь с небольшим шумом.</p>
<p><strong>И тут возникает вопрос… когда алгоритм является PAC-обучаемым?</strong> - то есть будет ли с ростом данных падать ошибка?</p>
<p>PAC-обучаемость для алгоритмов устанавливается путем проверки его <code class="docutils literal notranslate"><span class="pre">VC-размерности</span></code> (<em>размерности Вапника-Червоненкинса</em>) на конечность.</p>
<p><strong>VC-размерность</strong> — это число - максимальное количество примеров, которые алгоритм сможет разделить всеми возможными способами на две части (в случае классификации). Основной результат теории статистического обучения: если <code class="docutils literal notranslate"><span class="pre">VC-размерность</span></code> алгоритма конечна, то он является <code class="docutils literal notranslate"><span class="pre">PAC-обучаемым</span></code>. Интуитивно, можно построить хороший классификатор, если алгоритм может разделять данные на два класса всеми способами.</p>
<p>Деревья без обрезки не являются <code class="docutils literal notranslate"><span class="pre">PAC-обучаемыми</span></code>, потому что количество способов растёт неограниченно вместе с размером датасета. Классификатор ближайших соседей - является <code class="docutils literal notranslate"><span class="pre">PAC-обучаемым</span></code> когда точки “кучкуются” - так или иначе кластеризуются на группы классов (вероятность попасть в один класс падает вместе с ростом расстояния между точками).</p>
<p>Пример установления <em>VC-размерности</em> для линейного алгоритма (на плоскости): он может разделить датасет из трёх точек на две части. Чтобы разделить датасет из четырех точек на две части (всеми возможными способами), одной линии нашего алгоритма уже недостаточно. Следовательно, размерность такого алгоритма для плоскости равна 3 (конечна).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Достаточно одной линии&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Нужно две линии&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;Две неразделимые</span><span class="se">\n</span><span class="s2">одной линией части&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_54_0.png" src="_images/day_1_54_0.png" />
</div>
</div>
<p>Как ни странно, все эти знания нам в ближайшей пятидневной практике не понадобятся. Однако из всей этой теории (статистического обучения) вытекает следующее.</p>
<ol class="simple">
<li><p>Алгоритмы - работают! Правда, с некоторого количества примеров.</p></li>
<li><p>Работают не все алгоритмы. Существует теорема “Нет бесплатных обедов” (<code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">free</span> <span class="pre">lunch</span></code>-теорема), которая говорит, что универсальный алгоритм всегда потерпит неудачу (найдутся для него примеры). То есть мы должны “подтолкнуть” алгоритм некоторым знанием о задаче к решению. Именно поэтому линейный алгоритм на данных с ростом и весом проявил себя лучше.</p></li>
<li><p>Ошибку следует рассматривать из трех компонент: <strong>неустранимая ошибка</strong> (ошибка идеального классификатора, или <code class="docutils literal notranslate"><span class="pre">Bayes</span> <span class="pre">error</span> <span class="pre">rate</span></code>), <strong>ошибку аппроксимации</strong> (<em>смещение</em>) и <strong>ошибку оценивания</strong> (<em>разброс</em>). На этом остановимся подробнее в виде примера.</p></li>
</ol>
<blockquote>
<div><p>Вспомним, что мы можем выбирать алгоритмы. Пока неважно какие. Они могут давать разные множества моделей (как по количеству, так и по их сложности).</p>
</div></blockquote>
<p><strong>Неустранимая ошибка</strong> - это ошибка идеального классификатора на всех данных. Она даже ниже ошибки разметки человеком, и заложена самой природой данных - представьте что у нас есть описание “всех данных в мире” - и тогда <em>если существует хотя бы какая-нибудь вероятность</em> принадлежности примера более чем одному классу - неустранимая ошибка имеет место. Для детерминированных данных (не вероятностных) такая ошибка равна нулю.</p>
<p><strong>Ошибка смещения</strong> - это ошибка выбора класса алгоритма, возникает когда модели не способны приблизить данные достаточно.</p>
<p><strong>Ошибка разброса</strong> - это ошибка, возникающая вследствие того, что созданная алгоритмом модель - является только приближением к некоторой “идеальной” модели, но не является ей. Она появляется, когда предсказания отличаются от среднего не так же, как предсказываемая величина.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="n">x</span> <span class="o">**</span> <span class="mi">5</span> <span class="o">/</span> <span class="mi">100</span> <span class="o">**</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span> <span class="o">/</span> <span class="mi">10</span>  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span> 
<span class="p">])</span>

<span class="n">train_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Красным - наши данные. Вот уж какие есть&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Ось значений X&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Ось значений Y&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_57_0.png" src="_images/day_1_57_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="c1"># здесь мы подстраиваем данные под формат</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># библиотеки scikit-learn, о которой конечно же поговорим</span>
<span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Пусть наш алгоритм отдаёт нам линию&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yhat</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;Здесь очевидна ошибка смещения&quot;</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">70</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_58_0.png" src="_images/day_1_58_0.png" />
</div>
</div>
<p>“Подтолкнём” наш алгоритм ближе к задаче, дав возможность использовать различные степени X.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_power</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">X_powered</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[(</span><span class="n">x</span> <span class="o">**</span> <span class="n">power</span><span class="p">)</span> <span class="k">for</span> <span class="n">power</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_power</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span>
<span class="p">])</span>

<span class="n">yhat</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_powered</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_power</span><span class="p">),</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_powered</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_powered</span><span class="p">),</span> <span class="n">max_power</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yhat</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;Уже лучше, но мы знаем, что</span><span class="se">\n</span><span class="s2">это всего лишь приближение&quot;</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">70</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_60_0.png" src="_images/day_1_60_0.png" />
</div>
</div>
<p>Обогатим наш алгоритм и дадим возможность использовать (очень) большие степени.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">min_power</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">max_power</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">X_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[(</span><span class="n">x</span> <span class="o">**</span> <span class="n">power</span><span class="p">)</span> <span class="k">for</span> <span class="n">power</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">min_power</span><span class="p">,</span> <span class="n">max_power</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span>
<span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">yhat</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_new</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Мы выбрали слишком &quot;богатый&quot; на варианты способ!&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yhat</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;Совсем не то&quot;</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">70</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_62_0.png" src="_images/day_1_62_0.png" />
</div>
</div>
<p>Получается несколько случаев, как модель может подходить под данные:</p>
<ol class="simple">
<li><p>Недообучение: низкие метрики на тренировочном и тестовом множестве (которые частный случай “всех данных в мире”) - первый случай,</p></li>
<li><p>Переобучение: высокие метрики на тренировочном и низкие на тестовом - последний случай,</p></li>
<li><p>Генерализация: хорошие метрики на обоих множествах - будем считать второй случай,</p></li>
<li><p>Хорошие метрики на тестовом и слабые на тренировочном - редкий случай, иногда встречается когда тестовые данные слишком малы или сильно отличаются от тренировочных.</p></li>
</ol>
</div>
<div class="section" id="id12">
<h3>Заключение<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>Резюмируя этот наш раздел, важно знать вот что.</p>
<ol class="simple">
<li><p>Алгоритмы, которые мы будем в дальнейшем использовать, разные.</p></li>
<li><p>Соответственно, ошибаются они тоже по-разному.</p></li>
</ol>
<p>Иногда им они слишком простые, чтобы подойти под данные, иногда перебор сложные. Когда мы будем рассматривать конкретные практические алгоритмы, мы узнаем, что можно с этим делать.</p>
<blockquote>
<div><p>На этом поздравляю! Самое сложное в курсе уже пройдено. Дальше будет только практика, практика, и еще раз практика (которая критерий истины).</p>
</div></blockquote>
</div>
</div>
<hr class="docutils" />
<div class="section" id="python-jupyter-lab">
<h2>1.4 Инструментарий аналитика данных: python и jupyter lab<a class="headerlink" href="#python-jupyter-lab" title="Permalink to this headline">¶</a></h2>
<p>Для анализа данных можно использовать различные языки и инструменты, например языки <code class="docutils literal notranslate"><span class="pre">R</span></code>, <code class="docutils literal notranslate"><span class="pre">Julia</span></code>, визуальные инструменты <code class="docutils literal notranslate"><span class="pre">Dataiku</span></code> или <code class="docutils literal notranslate"><span class="pre">Orange3</span></code>. В сфере программного обеспечения часто можно найти множество альтернативных решений под каждую задачу.</p>
<p>Мы выбираем <code class="docutils literal notranslate"><span class="pre">python</span></code> и среду разработки <code class="docutils literal notranslate"><span class="pre">Jupyter</span> <span class="pre">Lab</span></code> не просто потому что они популярные. Популярность - это следствие наличия серьезной <em>экосистемы</em>, то есть набора инструментов и пакетов. <code class="docutils literal notranslate"><span class="pre">python</span></code> для анализа данных стал особо популярен в результате усилий Google и Facebook, которые выпустили большие полезные библиотеки для работы с данными. <code class="docutils literal notranslate"><span class="pre">Jupyter</span> <span class="pre">Lab</span></code> - это один самых частых инструментов ввиду своей простоты и при этом - удобства работы.</p>
<p>Все вот эти тетрадки были созданы с помощью <code class="docutils literal notranslate"><span class="pre">Jupyter</span> <span class="pre">Lab</span></code>, и его использует в практике очень много аналитиков. Так же как и <code class="docutils literal notranslate"><span class="pre">python</span></code>: порог вхождения у него не запредельный, а возможности, как у универсального языка с “кучей батареек” - практически неограничены (по-крайней мере для типичных задач).</p>
<div class="section" id="python-crash-course">
<h3>python crash course<a class="headerlink" href="#python-crash-course" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># переменные - ссылки на значения</span>

<span class="n">string_variable</span> <span class="o">=</span> <span class="s2">&quot;Это строка&quot;</span>
<span class="n">integer_variable</span> <span class="o">=</span> <span class="mi">42</span> <span class="c1"># целое число</span>
<span class="n">float_variable</span> <span class="o">=</span> <span class="mf">3.14</span> <span class="c1"># вещественное число</span>

<span class="n">string_variable</span><span class="p">,</span> <span class="n">integer_variable</span><span class="p">,</span> <span class="n">float_variable</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;Это строка&#39;, 42, 3.14)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Кортеж - упорядоченный неизменяемый список значений</span>

<span class="n">tuple_example</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="s2">&quot;Хопа&quot;</span><span class="p">)</span>
<span class="n">tuple_example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 23, &#39;Хопа&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Список - изменяемый набор значений</span>

<span class="n">list_example</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>

<span class="c1"># список можно &quot;срезать&quot; по индексам</span>
<span class="c1"># индексы всегда начинаются с нуля!</span>

<span class="n">list_example</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">list_example</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">list_example</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">list_example</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3, [1, 2], [4, 5], [1, 3, 5])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># словарь - множество пар &quot;ключ -&gt; значение&quot;</span>

<span class="n">dict_example</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;серебряный&#39;</span><span class="p">:</span> <span class="mf">100.100</span><span class="p">,</span>
    <span class="s1">&#39;золотой&#39;</span><span class="p">:</span> <span class="mf">200.200</span>
<span class="p">}</span>

<span class="n">dict_example</span><span class="p">[</span><span class="s1">&#39;серебряный&#39;</span><span class="p">],</span> <span class="n">dict_example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;платиновый&#39;</span><span class="p">,</span> <span class="s1">&#39;значение по умолчанию&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100.1, &#39;значение по умолчанию&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># элементам списков и словарей можно присваивать значения</span>

<span class="n">dict_example</span><span class="p">[</span><span class="s1">&#39;платиновый&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">list_example</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">159</span>

<span class="n">list_example</span><span class="p">,</span> <span class="n">dict_example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([1, 2, 159, 4, 5], {&#39;серебряный&#39;: 100.1, &#39;золотой&#39;: 200.2, &#39;платиновый&#39;: 159})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># циклы - по последовательности и по условию</span>

<span class="n">result</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
<span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">24</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">]:</span>
    <span class="n">result</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    
<span class="n">value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="mi">42</span><span class="p">:</span>
    <span class="n">value</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># не забудьте, а то цикл будет бесконечным без выхода</span>
<span class="nb">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A 2 12 B 
42
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># списки и словари можно инициализировать циклами</span>

<span class="n">range_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">*</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span>
<span class="n">range_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2</span><span class="p">)}</span>

<span class="n">range_list</span><span class="p">,</span> <span class="n">range_dict</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([2, 6, 10, 14, 18], {1: 3, 3: 5, 5: 7, 7: 9, 9: 11})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># функции... это почти то же, что и в математике - выход для входа</span>
<span class="c1"># а точнее - обособленный блок кода с параметрами</span>

<span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="n">function</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>40
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># класс - это описание объекта</span>
<span class="c1"># любой объект может иметь свойства и методы</span>

<span class="c1"># тут проще на примере</span>

<span class="k">class</span> <span class="nc">ExampleClass</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Такой метод называется конструктор</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># self - внутрення ссылка на текущий объект</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span>

    <span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
    
<span class="c1"># создадим объект - экземпляр класса</span>
<span class="n">example_object</span> <span class="o">=</span> <span class="n">ExampleClass</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># и вызовем его метод</span>
<span class="n">example_object</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>70
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># классы могут наследоваться, и обычно ожидается что объекты</span>
<span class="c1"># унаследованного класса &quot;ведут&quot; себя подобно объектам базового,</span>
<span class="c1"># но в деталях могут делать что-то другое</span>

<span class="k">class</span> <span class="nc">Inherited</span><span class="p">(</span><span class="n">ExampleClass</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>

<span class="n">example_object</span> <span class="o">=</span> <span class="n">Inherited</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">example_object</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>110
</pre></div>
</div>
</div>
</div>
<p>Как ни странно - это практически всё, что нам понадобится. Помимо этого, нам еще понадобится импорт библиотек, а вот в них уже “кладези всяких полезностей”. Выше мы видели, в какие чудеса они умеют, всё делают за нас, надо их только попросить :)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># вариант импорта из недр библиотеки</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>

<span class="c1"># другой вариант импорта </span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ну и продолжим, раз начали :)</span>

<span class="c1"># загрузим датасет из библиотеки</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># KMeans - это класс с методами</span>
<span class="n">clusterer</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># запись X[:, 1] - означает взять ВТОРУЮ колонку массива</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">clusterer</span><span class="o">.</span><span class="n">labels_</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_79_0.png" src="_images/day_1_79_0.png" />
</div>
</div>
</div>
<div class="section" id="id13">
<h3>Заключение<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">python</span></code> активно развивается. Из основных новшеств - это добавление спецификаций типов в объявления переменных (везде, где они объявляются). Мы пока это не используем, чтобы не усложнять код. Но выглядит это вот так (хотите - пользуйтесь, но потом не жалуйтесь:)). Учтите, эти подсказки по типам, в <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">3.6</span></code> на самом деле ни на что не влияют.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">example</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="n">example</span><span class="p">(),</span> <span class="n">example</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">example</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(None, 0, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example</span><span class="p">(</span><span class="s2">&quot;Hello, &quot;</span><span class="p">,</span> <span class="s2">&quot;world&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Hello, world&#39;
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id14">
<h2>1.5 Цикл моделирования и кросс-валидация<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>Теперь переходим к самой что ни на есть практике анализа данных. <strong>Цикл моделирования</strong> - это процесс из нескольких шагов, позволяющих из данных получить применяемую в практике модель. <strong>CRISP-DM</strong> - это сокращение слов <em>CRoss-Indrustry Standard Process for Data Mining</em> - кросс-индустриальный процесс анализа данных.</p>
<p>Процесс состоит из следующих шагов:</p>
<ol class="simple">
<li><p><strong>Понимание бизнес-цели.</strong> Зачем нам вообще анализ данных в текущей бизнес- или исследовательской задачи. На этом этапе должно быть ясно, зачем нужна модель, и какие у неё должны быть метрики качества.</p></li>
<li><p><strong>Разведочный анализ</strong>. Это ознакомление с данными, визуальный поиск зависимостей, формулировка гипотез о взаимосвязи.</p></li>
<li><p><strong>Подготовка данных</strong>. Это важный этап, на котором данные чистятся от битых значений и выбросов (они могут испортить модель), подготавливаются к удобному для моделирования виду.</p></li>
<li><p><strong>Моделирование</strong>. Построение моделей. Это всего-лишь приблизительно 20% времени от всего процесса, но как раз на этом этапе запускаются алгоритмы, которые выдают модели.</p></li>
<li><p><strong>Оценка</strong>. Оценка качества модели или ряда моделей. Оценка - это не только метрики, которые минимизировала модель, но еще и бизнес-метрики. Например, средняя ошибка в килограммах это одно, а в рублях - совсем другое. Только на этом этапе можно понять, пригодна ли модель к применению (эксплуатации).</p></li>
<li><p><strong>Внедрение</strong>. Это развертывание модели для применения. Например, чтобы или сайт, или пользователи, или организации - как-то смогли пользоваться предсказанием модели.</p></li>
<li><p><strong>Мониторинг</strong>. Это слежение за качеством уже применяемой модели. Обычно, по косвенным и производным признакам качества (растёт прибыль - хорошо!).</p></li>
</ol>
<p>В нашем курсе мы модели внедрять не будем (хотя и поговорим как можно). Важно заметить следующее:</p>
<blockquote>
<div><p>В этом процессе можно возвращаться с любого шага на любой шаг назад, но проскакивать вперед шаги нельзя! Иначе просто бессмысленно потратите время.</p>
</div></blockquote>
<div class="section" id="id15">
<h3>Пример<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id16">
<h4>1.5.1 Понимание задачи и целей<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h4>
<p>Давайте представим, что у нас есть цветочный магазин, который специализируется на цветках ириса, и предлагает их в трёх сортах: <code class="docutils literal notranslate"><span class="pre">Virginica</span></code>, <code class="docutils literal notranslate"><span class="pre">Versicolor</span></code> и <code class="docutils literal notranslate"><span class="pre">Setosa</span></code>. Мы хотели бы автоматически определять что за сорт, без участия каких-либо ботаников. К счастью, ботаники уже создали датасет из 150 цветков, в котором разметили их сорта.</p>
<p>Наша цель - создать модель, которая по признакам цветка определяла бы их сорт. <strong>Отбор моделей необходимо производить с учетом того, что сорта стоят по-разному!</strong></p>
</div>
<div class="section" id="id17">
<h4>1.5.2 Разведочный анализ<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h4>
<p>Ознакомление с данными. Первые попытки понять то, с чем мы имеем дело.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>

<span class="c1"># распечатаем какие есть признаки у данных</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;sepal length (cm)&#39;,
 &#39;sepal width (cm)&#39;,
 &#39;petal length (cm)&#39;,
 &#39;petal width (cm)&#39;]
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Где-то в интернетах нашлась хорошая картинка
<img alt="Iris" src="_images/iris.png" /></p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># загрузим данные в pandas-таблицу</span>

<span class="n">features_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">index</span><span class="p">]:</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]</span> \
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">))</span>
<span class="p">}</span>

<span class="n">features_data</span><span class="p">[</span><span class="s1">&#39;sort&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">features_data</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">sort</span><span class="p">]</span> <span class="k">for</span> <span class="n">sort</span> <span class="ow">in</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="p">]</span>

<span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">features_data</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;sort&#39;</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># и посмотрим на случайную выборку из 10 цветов</span>
<span class="n">frame</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>sort</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>5.0</td>
      <td>3.4</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.4</td>
      <td>3.9</td>
      <td>1.7</td>
      <td>0.4</td>
      <td>0</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>60</th>
      <td>5.0</td>
      <td>2.0</td>
      <td>3.5</td>
      <td>1.0</td>
      <td>1</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>45</th>
      <td>4.8</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.3</td>
      <td>0</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>55</th>
      <td>5.7</td>
      <td>2.8</td>
      <td>4.5</td>
      <td>1.3</td>
      <td>1</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>65</th>
      <td>6.7</td>
      <td>3.1</td>
      <td>4.4</td>
      <td>1.4</td>
      <td>1</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>103</th>
      <td>6.3</td>
      <td>2.9</td>
      <td>5.6</td>
      <td>1.8</td>
      <td>2</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>124</th>
      <td>6.7</td>
      <td>3.3</td>
      <td>5.7</td>
      <td>2.1</td>
      <td>2</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>127</th>
      <td>6.1</td>
      <td>3.0</td>
      <td>4.9</td>
      <td>1.8</td>
      <td>2</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>91</th>
      <td>6.1</td>
      <td>3.0</td>
      <td>4.6</td>
      <td>1.4</td>
      <td>1</td>
      <td>versicolor</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">frame</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>sort</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3</td>
    </tr>
    <tr>
      <th>top</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>50</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.843333</td>
      <td>3.057333</td>
      <td>3.758000</td>
      <td>1.199333</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.828066</td>
      <td>0.435866</td>
      <td>1.765298</td>
      <td>0.762238</td>
      <td>0.819232</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.300000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.100000</td>
      <td>0.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.100000</td>
      <td>2.800000</td>
      <td>1.600000</td>
      <td>0.300000</td>
      <td>0.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.800000</td>
      <td>3.000000</td>
      <td>4.350000</td>
      <td>1.300000</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.400000</td>
      <td>3.300000</td>
      <td>5.100000</td>
      <td>1.800000</td>
      <td>2.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.900000</td>
      <td>4.400000</td>
      <td>6.900000</td>
      <td>2.500000</td>
      <td>2.000000</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">frame</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>virginica     50
setosa        50
versicolor    50
Name: name, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Посмотрим на данные визуально, причем попарно</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">frame</span><span class="p">[</span><span class="n">features</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;name&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/day_1_94_0.png" src="_images/day_1_94_0.png" />
</div>
</div>
<p>Хорошо видно, что по некоторым признакам сорта образуют хорошие группы! А по некоторым - не очень.</p>
</div>
<div class="section" id="id18">
<h4>1.5.3 Подготовка данных<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h4>
<p>Вычищать из примеров мы ничего не будем. А вот признак <code class="docutils literal notranslate"><span class="pre">sepal</span> <span class="pre">width</span> <span class="pre">(cm)</span></code> - мы уберем, так как по этому признаку цветы очень схожи. Это на самом деле интуиция, которую мы проверим метриками качества в дальнейшем.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reduced_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="c1"># скопируем</span>
<span class="n">reduced_features</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;sepal width (cm)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Разобъем наш датасет на тренировочную и тестовую части. Пусть тестовая часть будет 25% от всего датасета.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">frame</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="n">frame</span><span class="o">.</span><span class="n">sort</span> <span class="c1"># об этом чуть ниже</span>
<span class="p">)</span>

<span class="s2">&quot;Столько у нас тренировочных цветов&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;Столько у нас тренировочных цветов&#39;, 112)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id19">
<h4>1.5.4 Моделирование<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h4>
<p>Возьмем простую модель классификации на основе ближайших соседей. Алгоритм предсказывает класс исходя из классов своих ближайших соседей для нового примера. Ближайшие соседи голосуют своим количеством за класс (какого класса рядом больше, тот и выиграл).</p>
<p>Этот алгоритм - на самом деле запоминает всю тренировочную выборку. Вспомним, что он является PAC-обучаемым, если данные по разным классам “кучкуются”, образуют некоторые кластеры. Судя по результатам визуального анализа - наш случай.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># создадим объект-классификатор и будем определять класс по 5 ближайшим соседям</span>
<span class="n">classifier_5</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># создадим второй, и будем определять уже по 10</span>
<span class="n">classifier_10</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># применим алгоритм к тренировочным данным</span>
<span class="n">classifier_5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">sort</span><span class="p">)</span>
<span class="n">classifier_10</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">sort</span><span class="p">)</span>

<span class="c1"># получим предсказания на тренировочном и тестовом множествах</span>
<span class="n">yhat_train_5</span> <span class="o">=</span> <span class="n">classifier_5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">])</span>
<span class="n">yhat_test_5</span> <span class="o">=</span> <span class="n">classifier_5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">])</span>

<span class="n">yhat_train_10</span> <span class="o">=</span> <span class="n">classifier_10</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">])</span>
<span class="n">yhat_test_10</span> <span class="o">=</span> <span class="n">classifier_10</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id20">
<h4>1.5.5 Проверка качества<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h4>
<p>Выберем в качестве метрики - процент правильно отмеченных цветов. Чем это число выше - тем классификатор лучше. Потом учтем так же, что разные цветы стоят по-разному!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;classifier_5&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_train_5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;classifier_5&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_test_5</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;classifier_10&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_train_10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;classifier_10&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_test_10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>classifier_5 train 0.97
classifier_5 test 0.97
classifier_10 train 0.96
classifier_10 test 0.97
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># измерим теперь ошибку в деньгах</span>
<span class="c1"># следующая функция подсчитывает таблицу ошибок по классам</span>

<span class="n">prices</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;setosa&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;versicolor&#39;</span><span class="p">:</span> <span class="mi">120</span><span class="p">,</span>
    <span class="s1">&#39;virginica&#39;</span><span class="p">:</span> <span class="mi">200</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">money_error</span><span class="p">(</span><span class="n">true_set</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
    <span class="n">cost_true</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
        <span class="n">prices</span><span class="p">[</span><span class="n">true_set</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">]]</span> \
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">true_set</span><span class="o">.</span><span class="n">index</span>
    <span class="p">])</span>
    <span class="n">cost_predicted</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
        <span class="n">prices</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">prediction</span><span class="p">)]]</span> \
        <span class="k">for</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="n">predictions</span>
    <span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Должно стоить </span><span class="si">%d</span><span class="s2">, а предсказано </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
        <span class="n">cost_true</span><span class="p">,</span> <span class="n">cost_predicted</span>
    <span class="p">))</span>

<span class="n">money_error</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">yhat_test_5</span><span class="p">)</span>
<span class="n">money_error</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">yhat_test_10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Должно стоить 5360, а предсказано 5280
Должно стоить 5360, а предсказано 5280
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># а посмотрим-ка, как алгоритмы ошибаются</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;5 neighbors&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_test_5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;10 neighbors&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_test_10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5 neighbors
[[12  0  0]
 [ 0 13  0]
 [ 0  1 12]]

10 neighbors
[[12  0  0]
 [ 0 13  0]
 [ 0  1 12]]
</pre></div>
</div>
</div>
</div>
<p>На главной диагонали это матрицы стоит число <em>правильно</em> классифицированных примеров, а в остальных ячейках - перепутанные при предсказании метки (по горизонтали - актуальные значения, а по вертикали - предсказанные). То есть в ячейке (3 по вертикали, 2 по горизонтали) стоит число примеров, отнесенных моделью к классу 3 вместо 2. А теперь, как и было обещано, проверим со качество всеми признаками (на 10 соседях).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">sort</span><span class="p">)</span>
<span class="n">yhat_test</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span> <span class="n">yhat_test</span><span class="p">))</span>
<span class="n">money_error</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">yhat_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[12  0  0]
 [ 0 13  0]
 [ 0  2 11]]
Должно стоить 5360, а предсказано 5200
</pre></div>
</div>
</div>
</div>
<p>Ну что ж, так и есть, тот признак слегка портил модель. На основании исследования метрик, можно принимать решение, какую модель внедрять.</p>
<blockquote>
<div><p>На этом курсе каждая команда должна пройти эти пять шагов как минимум. Мы приложим все усилия, чтобы у вас это получилось.</p>
</div></blockquote>
<p>Рассмотрим что такое <strong>кросс-валидация</strong>.</p>
<p><strong>Кросс-валидация</strong> - это метод подсчета метрик модели, используя все доступные данные. Делается это для того, чтобы снизить влияние разбиения данных на принятие конечного решения.</p>
<p>Кросс-валидация делается так:</p>
<ol class="simple">
<li><p>Всё множество разбивается на <code class="docutils literal notranslate"><span class="pre">K</span></code> частей,</p></li>
<li><p>На всех частях кроме одной обучается модель,</p></li>
<li><p>Качество проверяется на одной отложенной части,</p></li>
<li><p>Процесс повторяется <code class="docutils literal notranslate"><span class="pre">K</span></code> раз, пока все части не побудут тестовыми.</p></li>
</ol>
<p>Здесь важно пояснить. Если с кросс-валидацией для регрессии всё просто - бьем на части, учимся на одних, проверяем качество на отложенной, то с классификацией всё почти так же… за исключением того момента, что разбиение на части производится <em><strong>стратифицированно</strong></em>: датасет бьется на части так, чтобы соотношение классов в каждой части сохранялось по отношению ко всему датасету. То есть если у нас 1/1/1 для всех цветков ириса, то при разбиении на части этот баланс будет сохранен.</p>
<blockquote>
<div><p>ВНИМАНИЕ! Метод <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> из <em>scikit-learn</em> умеет делать стратифицированное разбиение при классификации (с помощью параметра <code class="docutils literal notranslate"><span class="pre">stratify</span> <span class="pre">=</span> <span class="pre">y</span></code>). Это нужно. <strong>В курсе иногда “наивно” используется <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> (простое перемешивание), что не до конца корректно при классификации. Обращайте на это внимание. Как перемешаны данные - важно.</strong></p>
</div></blockquote>
<p>“В природе” так же встречаются и сильно несбалансированные датасеты - для работы с этим используются отдельные техники: либо классы балансируют, либо работают с регуляризацией (штрафами модели на коэффициенты), либо используют веса для примеров (вес редкого примера выше, такие веса можно передавать третьим параметром <code class="docutils literal notranslate"><span class="pre">fit</span></code> у некоторых алгоритмов).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
    <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">X</span><span class="o">=</span><span class="n">frame</span><span class="p">[</span><span class="n">reduced_features</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">frame</span><span class="o">.</span><span class="n">sort</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span> <span class="c1"># пять частей</span>
<span class="p">)</span>

<span class="n">metrics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 1.        ])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ожидаемое среднее качество </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Разброс среднего качества </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ожидаемое среднее качество 0.97
Разброс среднего качества 0.01
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id21">
<h3>Заключение<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>В заключение следует отметить пару вещей:</p>
<ol class="simple">
<li><p>Процесс CRISP-DM не гарантирует качественной модели, но без него вы точно её не получите,</p></li>
<li><p>Модели имеет смысл кросс-валидировать, чтобы использовать все доступные данные. Часто это используют при отборе гиперпараметров - в нашем случае это число ближайших соседей. Но об этом будет еще в нашем курсе позже.</p></li>
</ol>
</div>
</div>
<div class="section" id="id22">
<h2>1.6 Обзор всего курса на примерах предсказаний<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h2>
<p>Этот обзорный блок о том, с чем курс нас познакомит.</p>
<div class="section" id="id23">
<h3>Второй день - обучение с учителем<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<p>В основном, на моделях из библиотеки <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. Начнем все же со специализированных библиотек работы с массивами, табличными данными и их визуализацией, и уделим внимание <em>Exploratory Data Analysis</em> (EDA, разведочный анализ данных). Он в первую очередь нужен для того, чтобы понять что делать с имеющимися признаками и с какого алгоритма имеет смысл начинать.</p>
<p>Далее на примере задач регрессии и классификации, мы рассмотрим такие алгоритмы, как:</p>
<ul class="simple">
<li><p>линейный. В случае классификации он “пытается” линейно разделить классы.</p></li>
</ul>
<p><img alt="linear_iris" src="_images/linear_iris.png" /></p>
<ul class="simple">
<li><p>деревья решений и ансамбли деревьев решений, которые делают разделение на основе “правил”.</p></li>
</ul>
<p><img alt="tree_iris" src="_images/tree_iris.png" /></p>
<ul class="simple">
<li><p>ближайших соседей, когда решение принимается исходя из схожих примеров.</p></li>
</ul>
<p><img alt="knn_iris" src="_images/knn_iris.png" /></p>
<p>Также на примере ближайших соседей мы посмотрим на базовые способы обработки текстов. С помощью размеченных категорий датасета переписок - мы научимся относить их к определенным классам.</p>
<ul class="simple">
<li><p>неглубоких нейросетей, которые сами ищут такое признаковое представление, чтобы классы были разделимы.</p></li>
</ul>
<p><img alt="ann_iris" src="_images/ann_iris.png" /></p>
</div>
<div class="section" id="id24">
<h3>Третий день - задачи без учителя и временные ряды<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h3>
<p>День будет посвящен работе с неразмеченными данными, без меток правильных ответов - да, с такими данными тоже можно что-то проделывать полезное. Но все же начнется со способов автоматического отбора моделей, а затем будут рассмотрены задачи:</p>
<ul class="simple">
<li><p>понижения размерности и мы узнаем как можно извлекать из неразмеченных текстов наиболее характеризующие их слова.</p></li>
<li><p>кластеризации, то есть сумеем отнести примеры к той или иной группе, посмотрим один из способов как найти наилучшее число групп,</p></li>
</ul>
<p><img alt="kmeans_iris" src="_images/kmeans_iris.png" /></p>
<ul class="simple">
<li><p>поиска аномалий в данных, то есть поиска с помощью модели сильно отличающихся от остальных примеров.</p></li>
</ul>
<p>Еще мы узнаем как можно продолжать одномерные временные ряды:</p>
<p><img alt="prophet_airpassengers" src="_images/prophet_airpassengers.png" /></p>
<p>и как можно использовать предсказаний одних моделей как вход для других моделей (на примере погоды).</p>
</div>
<div class="section" id="id25">
<h3>Четвертый день - нейросети<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<p>Этот день будет полностью нейросетям и некоторым задачам, которые можно решать с помощью них библиотекой <code class="docutils literal notranslate"><span class="pre">keras</span></code>. Классические регрессию и классификацию можно решать не только на табличных данных, но и на изображениях, текстах и многомерных временных рядах, например мы рассмотрим:</p>
<ul class="simple">
<li><p>задачу сжатия представления входных данных до вектора и обратного преобразования с помощью сетей-автокодировщиков.</p></li>
</ul>
<p><img alt="ae_fashion" src="_images/ae_fashion.png" /></p>
<ul class="simple">
<li><p>задачу сегментации объектов (например наручных часов на изображении) с помощью сети <code class="docutils literal notranslate"><span class="pre">Unet</span></code>.</p></li>
</ul>
<p><img alt="unet_watches" src="_images/unet_watches.png" /></p>
<ul class="simple">
<li><p>готовые сети работы с изображениями и текстами. Например, построим простого вопросно-ответного-бота. Ему будут известны и вопросы, и ответы, но вопросы могут быть произвольными. Узнаем как возможно извлекать именованные сущности из текста (имена, события и др.), или суммаризировать тексты (извлекать основное из них).</p></li>
<li><p>посмотрим, как отдавать сети последовательные многомерные данные (не один ряд, а несколько) - на примере всё той же погоды.</p></li>
</ul>
<p><img alt="gru_weather" src="_images/gru_weather.png" /></p>
</div>
<div class="section" id="id26">
<h3>Пятый день - интерпретация, презентация и внедрение моделей<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h3>
<p>А пятый день посвящен тому, что модель - это еще не окончание всех дел, а только начало. В частности узнаем, что:</p>
<ul class="simple">
<li><p>предсказания моделей можно и нужно интепретировать.</p></li>
<li><p>модели можно и нужно разворачивать как сервис, и делать для них интерактивные презентации.</p></li>
<li><p>так как модели работают с ошибкой, необходимо убеждаться что они действительно улучшают процесс. Делается это через особый дизайн экспериментов.</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "py35"
        },
        kernelOptions: {
            kernelName: "py35",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'py35'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="README.html" title="previous page">Курс “Введение в анализ данных и машинное обучение”</a>
    <a class='right-next' id="next-link" href="day_2.html" title="next page">День второй - анализ данных</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Sazonov Andrey<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>